+++
title = "Projects"
description = "Research Projects"
date = "2020-11-03"
aliases = ["projects", "research-pprojects", "research"]
author = "Souvik Kundu"
+++


#### 1. Reducing Spiking Activity of SNNs via Brain-Inspired Learning 
We propose an attention-guided compression scheme yield extremely energy-efficient SNNs.
{{< rawhtml >}}
<img src="/images/wacv.jpg" alt="drawing" width="500"/>
{{< /rawhtml >}}

(*WACV 2021*)

#### 2. Making Compressed Models Adversarially Robust
We propose a one-shot training framework to generate robust yet compressed DNN models.
{{< rawhtml >}}
<img src="/images/asp_dac2021.jpg" alt="drawing" width="500"/>
{{< /rawhtml >}}

(*ASP-DAC 2021*)

#### 3. Are Dense CNN Kernels Really Necessary?
A study of sparsely represented kernels, where we propose hardware friendly sparse models enabling low cost data-transfer from DRAM 

{{< rawhtml >}}
<img src="/images/IEEE_TC.jpg" alt="drawing" width="300"/>
{{< /rawhtml >}}

(*IEEE TC  2020, Allerton 2019, Best poster at USC research festival 2019*)

#### 4. Making MCA Based Crossbar Array More Compact
We propose a new form of pre-defined sparsity that can reduce the cross bar array size drastically, thus helps in making RRAM based ML accelerators
{{< rawhtml >}}
<img src="/images/isvlsi2019.jpg" alt="drawing" width="300"/>
{{< /rawhtml >}}

(*ISVLSI 2019*)